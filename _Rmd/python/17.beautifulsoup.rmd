---
layout: post
title: "[Python] BeautifulSoup"
date: "2018-10-01"
excerpt: "웹 크롤링을 해보자"
output: github_document
tag:
    [python, beautifulsoup]
comments: true
categories:
  Python
---


```{r setup, include = FALSE}
library(reticulate)
use_python("/Users/Deokhee/anaconda/bin/")
```

## BeautifulSoup

`BeautifulSoup`는 웹에 있는 데이터를 크롤링 혹은 스크랩핑할 때 사용하는 라이브러리이다. 사용법을 알아보기 앞서 라이브러리가 설치되어있지 않다면 설치부터 해주자.

```
# Anaconda Prompt서 다음을 실행시켜준다.
$ pip install beautifulsoup4
```

***

### tag로 추출하기

 설치가 되었다면 사용법에 대해 알아보자.

```{python}
from bs4 import BeautifulSoup

# html 예제 생성
html = """
            <html>
                <body>
                    <h1> Data Science </h1>
                        <p> data analysis 1 </p>
                        <p> data analysis 2 </p>
                        <p> data analysis 3 </p>

                </body>
            </html>
        """

soup = BeautifulSoup(html,"html.parser") # html.parser라는 분석기를 사용
# 단점은 웹에서 원하는 데이터를 바로 끌고오지 못하고 html을 들고와서 작업을 해야한다.
#
# 원하는 태그 내용을 가져오기 
## h1 데이터 추출
h1 = soup.html.body.h1 # html -> body -> h1
print(h1.string) # 문자열만 들고오기

## p 태그 데이터 추출
p1 = soup.html.body.p 
print(p1.string) # p tag가 3개 있지만 첫번째 것만 추출됌

## 2번째 p tag 추출
p2 = p1.next_sibling.next_sibling # next_sibling만 추출하면 /n이 추출되므로 2번 사용한다.
print(p2.string)

# 3번째 p tag 추출
p3 = p2.next_sibling.next_sibling 
print(p3.string)
```

***

### 속성값으로 추출하기

`html`에는 id, class 등의 여러 속성을 가지고 있다. 속성으로 데이터를 추출하면 더 태그로 추출하는 것 보다 더 편리할 수 있다. 그럼 속성값으로 웹데이터를 추출해보자.

```{python}
from bs4 import BeautifulSoup

html = """
        <html>
            <body>
                <h1 id = 'title'> beautifulsoup </h1>
                <p id = 'subtitle'> web scraping </p>
                <p> web data extraction기 </p>
            </body>
        </html>
       """
soup = BeautifulSoup(html,'html.parser')

# .find() 사용
## title 추출
title = soup.find(id = 'title')
print(title.string)


sub = soup.find(id = 'subtitle').string ## subtitle 추출
print(sub)
```

다른 속성을 가진 `html` 예제를 만들어 값을 추출해보자.

```{python}
from bs4 import BeautifulSoup

html = """
        <html>
            <body>
                <ul>
                    <li><a href='http://www.google.com'> Google </a></li>
                    <li><a href='http://www.amazon.com'> Amazon </a></li>
            <body>
        </html>
       """

soup = BeautifulSoup(html,'html.parser')

# tag로 찾기
a_tag = soup.html.body.ul.li.a
print(a_tag.string) # 1번째 anchor tag가 추출됌

print(soup.find('a').string) # find도 마찬가지 첫번째만 찾아주고 2번째 a를 찾지 못한다


print(soup.find_all('a')) # .find_aLl() 을 사용하여 모든 achor tag 추출


for i in soup.find_all('a'): # 루프 구조로 string만 추출할 수 있다.
  print(i.string)
```

위의 예제에서 url 주소만 추출해보자

```{python}
from bs4 import BeautifulSoup

html = """
        <html>
            <body>
                <ul>
                    <li><a href='http://www.google.com'> Google </a></li>
                    <li><a href='http://www.amazon.com'> Amazon </a></li>
            <body>
        </html>
       """

soup = BeautifulSoup(html,'html.parser')

# a tag 추출(첫번째만 추출된다)
a = soup.a
print('href' in a.attrs) # a tag에 href 속성이 있는지 확인
print(a.attrs) # a tag의 속성값 확인


print(a['href']) # value(url 값)만 확인 1
print(a.attrs['href']) # value(url 값)만 확인 2


lnk = soup.find_all('a') # 전체 url 값을 추출
for i in lnk:
  print(i.attrs['href'])
```


